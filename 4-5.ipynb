{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aarunku5/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import spacy\n",
    "import math\n",
    "\n",
    "import string\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b72efcc90c744e7a64b0c14f699acc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=202), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf719a9a9214139bd0fadfc8e4ce0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc3202c07c7477e83c7cf0cf61b4370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=202), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_wino = pd.read_csv('./test_good_101_1.csv')\n",
    "nlp = spacy.load(\"en_trf_bertbaseuncased_lg\")\n",
    "words=pd.DataFrame()\n",
    "frames=[df_wino['sentence1'],df_wino['sentence2']]\n",
    "words['full'] = pd.concat(frames)\n",
    "words.reset_index(inplace = True) \n",
    "words['casewords'] = words['full'].str.lower()\n",
    "words['wsw'] = words['casewords'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "words['nopunc'] = words['wsw'].str.replace(\"'\", \"\")\n",
    "words['nopunc'] = words['nopunc'].str.replace(\".\", \"\")\n",
    "words['nopunc'] = words['nopunc'].str.replace(\",\", \"\")\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "words['text_lemmatized'] = words.nopunc.apply(lemmatize_text)\n",
    "words['final']=\"NaN\"\n",
    "def final(x):\n",
    "    makeitastring = ' '.join(map(str, x))\n",
    "    makeitastring=makeitastring.replace(\",\",\"\")\n",
    "    makeitastring=makeitastring.replace(\"'\",\"\")\n",
    "    makeitastring=makeitastring.replace(\"[\",\"\")\n",
    "    makeitastring=makeitastring.replace(\"]\",\"\")\n",
    "    return makeitastring\n",
    "for i in tqdm(range(len(words))):    \n",
    "    column=['text_lemmatized']\n",
    "    row=[i]\n",
    "    words.loc[i,'final']=final(words.loc[i,'text_lemmatized'])\n",
    "words['fullnopunc'] = words['full'].str.replace(\"'\", \"\")\n",
    "words['fullnopunc'] = words['fullnopunc'].str.replace(\".\", \"\")\n",
    "words['fullnopunc'] = words['fullnopunc'].str.replace(\",\", \"\")\n",
    "words['label']='NaN'\n",
    "for i in tqdm(range(len(df_wino))):\n",
    "    words.loc[i,'label']=df_wino.loc[i,'gold_label']\n",
    "    words.loc[(i+len(df_wino)),'label']=df_wino.loc[i,'gold_label']\n",
    "words.to_csv('./test_good_101_1_words.csv', index = False)\n",
    "e=pd.DataFrame(columns=['label','final','fullnopunc'])\n",
    "n=pd.DataFrame(columns=['label','final','fullnopunc'])\n",
    "c=pd.DataFrame(columns=['label','final','fullnopunc'])\n",
    "#split test labels\n",
    "for i in tqdm(range(len(words))):\n",
    "    l=words.loc[i,'label']\n",
    "    new_row={'label':words.loc[i,'label'],'final':words.loc[i,'final'],'fullnopunc':words.loc[i,'fullnopunc']}\n",
    "    if(l=='entailment'):\n",
    "        e=e.append(new_row, ignore_index=True)\n",
    "    elif(l=='neutral'):\n",
    "        n=n.append(new_row, ignore_index=True)\n",
    "    else:\n",
    "        c=c.append(new_row,ignore_index=True)\n",
    "e.to_csv('./test_good_101_1_wordse.csv', index = False)\n",
    "n.to_csv('./test_good_101_1_wordsn.csv', index = False)\n",
    "c.to_csv('./test_good_101_1_wordsc.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "104\n",
      "50\n",
      "101\n",
      "202\n"
     ]
    }
   ],
   "source": [
    "print(len(e))\n",
    "print(len(n))\n",
    "print(len(c))\n",
    "print(len(df_wino))\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e0d1b04d914aa6b84b9afe3bfbf544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=202), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006532405592774371"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gwords=pd.read_csv(\"./test_good_101_1_words.csv\")\n",
    "size=len(gwords)\n",
    "WSIML=0.5\n",
    "sentence=gwords['fullnopunc']\n",
    "lists=[]\n",
    "vals=[]\n",
    "for x in tqdm(range(len(sentence))):\n",
    "    arr=[]\n",
    "    s=sentence[x]\n",
    "    word = s.split()\n",
    "    length=len(word)\n",
    "    sl=0\n",
    "    for i in (range(length)):\n",
    "        sm=0\n",
    "        for j in (range(length)):\n",
    "            if(i!=j):\n",
    "                sm=sm+nlp(word[i]).similarity(nlp(word[j]))\n",
    "        sm=sm/length\n",
    "        arr.append(sm)\n",
    "        sm=abs(sm-WSIML)\n",
    "        sl=sl+sm\n",
    "    lists.append(arr)\n",
    "    vals.append(size/sl)\n",
    "\n",
    "len(gwords)/pd.Series(vals).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4ed18416e74167a98410c79387b5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285753763f8247ca93492687d0a2acf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23856b380017470f90779956af41fa95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a5c3924bad492a99eceeec28024772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071fca38f539416ea0d1c5288f85fc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156d9b9a8a544c1aa5bf124d84030822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffe8e5343b94f849870e6a267f7e7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec13fb7becd3436580cea64ed4eb7209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8082cc69ff424181527e68e7e81d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39d00abe24348e88db3082b8e07dac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[1.5078036884658743, 1.7755167605086704, 2.158818625811296, 2.75318032167654, 3.774922918891222, 5.759273105786393, 9.559867544343893, 11.618984979000448, 7.11004329237453]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72594968d52b4472b870c4eed73c0210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1, 9, 4, 6, 2, 6, 1, 8, 15, 4, 1, 7, 11, 1, 5, 4, 12, 3, 8, 11, 11, 11, 2, 3, 3, 4, 2, 19, 1, 7, 18, 6, 2, 8, 2, 0, 6, 5, 4, 6, 31, 38, 5, 16, 4, 2, 5, 33, 12, 16, 16, 4, 5, 10, 1, 2, 9, 8, 3, 5, 6, 1, 4, 0, 2, 1, 18, 9, 5, 2, 9, 1, 4, 6, 5, 0, 17, 6, 19, 16, 2, 2, 9, 7, 13, 7, 1, 4, 18, 3, 1, 2, 10, 6, 7, 1, 7, 8, 10, 7, 3]\n",
      "0.06756992585061462\n",
      "0.13950276243093923\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12328691e4af491f9cb80df09f08f542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.731594078373792, 0.7071323328916573, 0.6084232871713664, 0.83258588081206, 0.8659693743389781, 0.8373076248945541, 0.785089759464352, 0.711765019821002, 0.7204732725577601, 0.7578399374810542, 0.8200743273283415, 0.8207343656307879, 0.7751139141883853, 0.8816582624539723, 0.8842817887763237, 0.9313493167365009, 0.7348446484908576, 0.6534945662526068, 0.673514136586978, 0.6552793109798888, 0.8283842707943571, 0.8180516428091832, 0.7768818276487424, 0.6008899534498305, 0.6728583850337511, 0.726095322785707, 0.8581615607466013, 0.7653848492190759, 0.9160845289055501, 0.8116007957688067, 0.684753683096059, 0.7966191692278501, 0.8166835717099845, 0.8084913075183292, 0.7762492988386241, 0.6970762385609213, 0.5681490553821698, 0.8961349735801857, 0.8999271642928709, 0.5096694766383505, 0.7170249399407199, 0.7647675868650998, 0.8735501884536386, 0.7822725363055315, 0.6545521273466435, 0.7270936806490413, 0.8528961190603768, 0.6776162638926507, 0.5409919781502396, 0.6502575025945189, 0.624149915062531, 0.9257596439245793, 0.7388064269383022, 0.8198391570910845, 0.776633768023106, 0.7848145489065016, 0.8410949216664746, 0.7751658431423176, 0.7500764781926358, 0.5957781509824064, 0.6507006563895287, 0.7400036968410421, 0.6735214649455267, 0.9184318766002475, 0.912823817407538, 0.7849661811924393, 0.9184736148443483, 0.6411643641375037, 0.7781180599056785, 0.7401543592656478, 0.8776788908606344, 0.8024378133598878, 0.9721299529197684, 0.8884028707571245, 0.8286310229719765, 0.8321954877204928, 0.7384926056315341, 0.8771393275234044, 0.5581247498071651, 0.41466710434913023, 0.8029704691772008, 0.8364929895875641, 0.8488809407720317, 0.8193730411463753, 0.7572613188556216, 0.6738247196750649, 0.7185548510307104, 0.7829774385720393, 0.5384532709709288, 0.8307028056581782, 0.6843127390978571, 0.8037534280119638, 0.6595783820755181, 0.8281041584728596, 0.7459944472536992, 0.8840793189013623, 0.8715819700198101, 0.7299922867497267, 0.548122255351549, 0.7879105758948725, 0.8938540294399576]\n",
      "0.0010566950356027988\n"
     ]
    }
   ],
   "source": [
    "df_testgood=pd.read_csv(\"./test_good_101_1.csv\")\n",
    "\n",
    "SIML=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "arr=[]\n",
    "df = pd.DataFrame(columns=['p', 'h'], data=df_testgood[['sentence1','sentence2']].values)\n",
    "df['p'] = df['p'].str.replace(\"'\", \"\")\n",
    "df['p'] = df['p'].str.replace(\".\", \"\")\n",
    "df['p'] = df['p'].str.replace(\",\", \"\")\n",
    "df['h'] = df['h'].str.replace(\"'\", \"\")\n",
    "df['h'] = df['h'].str.replace(\".\", \"\")\n",
    "df['h'] = df['h'].str.replace(\",\", \"\")\n",
    "\n",
    "for x in tqdm(range(len(SIML))):\n",
    "    dr=0\n",
    "    for i in tqdm(range(len(df_testgood))):        \n",
    "        dr=dr+abs(((nlp(df.loc[i,'p'])).similarity(nlp(df.loc[i,'h'])))-SIML[x])\n",
    "    arr.append(len(df_testgood)/dr)\n",
    "print(arr)\n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "garr=[]\n",
    "\n",
    "df = pd.DataFrame(columns=['p', 'h'], data=df_testgood[['sentence1','sentence2']].values)\n",
    "df['p'] = df['p'].str.replace(\"'\", \"\")\n",
    "df['p'] = df['p'].str.replace(\".\", \"\")\n",
    "df['p'] = df['p'].str.replace(\",\", \"\")\n",
    "df['h'] = df['h'].str.replace(\"'\", \"\")\n",
    "df['h'] = df['h'].str.replace(\".\", \"\")\n",
    "df['h'] = df['h'].str.replace(\",\", \"\")\n",
    "\n",
    "for i in tqdm(range(len(df_testgood))):         \n",
    "    garr.append(abs((len((df.iloc[i]['p']).split()))-(len((df.iloc[i]['h']).split()))))\n",
    "print(garr)\n",
    "print(pd.Series(garr).std()/len(df_testgood))    \n",
    "print(len(garr)/(pd.Series(garr).sum()+1))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "gsarr=[]\n",
    "df = pd.DataFrame(columns=['p', 'h'], data=df_testgood[['sentence1','sentence2']].values)\n",
    "df['p'] = df['p'].str.replace(\"'\", \"\")\n",
    "df['p'] = df['p'].str.replace(\".\", \"\")\n",
    "df['p'] = df['p'].str.replace(\",\", \"\")\n",
    "df['h'] = df['h'].str.replace(\"'\", \"\")\n",
    "df['h'] = df['h'].str.replace(\".\", \"\")\n",
    "df['h'] = df['h'].str.replace(\",\", \"\")\n",
    "\n",
    "for i in tqdm(range(len(df_testgood))):        \n",
    "    gsarr.append(abs(((nlp(df.loc[i,'p'])).similarity(nlp(df.loc[i,'h'])))))\n",
    "print(gsarr)\n",
    "    \n",
    "print(pd.Series(gsarr).std()/len(df_testgood))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
